import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from sklearn.cluster import KMeans, DBSCAN
from sklearn.datasets import make_blobs, make_moons, make_circles
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from scipy.spatial.distance import cdist
import pandas as pd


# Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù†
st.markdown("""
    <style>
    .stTextInput > div > div > input {
        text-align: right;
        direction: rtl;
    }
    .stTextArea > div > div > textarea {
        text-align: right;
        direction: rtl;
    }
    .element-container:has(div.stMarkdown) {
        text-align: right;
        direction: rtl;
    }
    .stButton > button {
        float: right;
    }
    .stTabs [data-baseweb="tab-list"] {
        flex-direction: row-reverse;
    }
    .stTabs [data-baseweb="tab"] {
        direction: rtl;
    }
    .stTextInput > label {
        text-align: right;
        direction: rtl;
    }
    .stTextArea > label {
        text-align: right;
        direction: rtl;
    }
    h2, h3 {
        text-align: right !important;
        direction: rtl !important;
    }
    h1 {
        text-align: center !important;
    }
    </style>
""", unsafe_allow_html=True)

# Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Torque Clustering
class TorqueClustering:
    def __init__(self, n_clusters=3, max_iter=100, tol=1e-4):
        self.n_clusters = n_clusters
        self.max_iter = max_iter
        self.tol = tol
        
    def fit(self, X):
        n_samples = X.shape[0]
        n_features = X.shape[1]
        
        # Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø±Ø§Ú©Ø² Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
        centers = X[np.random.choice(n_samples, self.n_clusters, replace=False)]
        
        for _ in range(self.max_iter):
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§
            distances = cdist(X, centers)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú¯Ø´ØªØ§ÙˆØ±
            torque = np.zeros((n_samples, n_features))
            for i in range(n_samples):
                for j in range(self.n_clusters):
                    torque[i] += (X[i] - centers[j]) * (1 / (distances[i, j] + 1e-10))
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø±Ø§Ú©Ø²
            new_centers = np.zeros_like(centers)
            for j in range(self.n_clusters):
                mask = distances.argmin(axis=1) == j
                if mask.any():
                    new_centers[j] = X[mask].mean(axis=0)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ
            if np.linalg.norm(new_centers - centers) < self.tol:
                break
                
            centers = new_centers
            
        self.centers_ = centers
        self.labels_ = distances.argmin(axis=1)
        return self

# ØªØ§Ø¨Ø¹ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ
def generate_data(data_type, n_samples, noise):
    if data_type == "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø±ÙˆÛŒ":
        return make_blobs(n_samples=n_samples, centers=3, cluster_std=noise, random_state=42)
    elif data_type == "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ù„Ø§Ù„ÛŒ":
        return make_moons(n_samples=n_samples, noise=noise, random_state=42)
    elif data_type == "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ù„Ù‚ÙˆÛŒ":
        return make_circles(n_samples=n_samples, noise=noise, factor=0.5, random_state=42)

# ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
def evaluate_clustering(X, labels):
    if len(np.unique(labels)) > 1:
        silhouette = silhouette_score(X, labels)
        calinski = calinski_harabasz_score(X, labels)
        davies = davies_bouldin_score(X, labels)
    else:
        silhouette = calinski = davies = 0
    return silhouette, calinski, davies

# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø§ØµÙ„ÛŒ
st.title("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ")
st.markdown("""
Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø§ Ø¨Ø§ Ù‡Ù… Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
""")

# ØªØ¨â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
tab1, tab2, tab3 = st.tabs(["Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§", "ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§", "Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡"])

with tab1:
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    col1, col2, col3 = st.columns(3)
    with col1:
        data_type = st.selectbox(
            "Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡:",
            ["Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø±ÙˆÛŒ", "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ù„Ø§Ù„ÛŒ", "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ù„Ù‚ÙˆÛŒ"]
        )
    with col2:
        n_samples = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§:", 100, 1000, 500)
    with col3:
        noise = st.slider("Ù†ÙˆÛŒØ²:", 0.01, 0.5, 0.1)
    
    # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    X, y_true = generate_data(data_type, n_samples, noise)
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§
    col1, col2, col3 = st.columns(3)
    with col1:
        n_clusters = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§:", 2, 10, 3)
    with col2:
        eps = st.slider("ÙØ§ØµÙ„Ù‡ Ø§Ù¾Ø³ÛŒÙ„ÙˆÙ† (DBSCAN):", 0.1, 1.0, 0.3)
    with col3:
        min_samples = st.slider("Ø­Ø¯Ø§Ù‚Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ (DBSCAN):", 2, 20, 5)
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§
    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)
    dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
    torque = TorqueClustering(n_clusters=n_clusters).fit(X)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    kmeans_metrics = evaluate_clustering(X, kmeans.labels_)
    dbscan_metrics = evaluate_clustering(X, dbscan.labels_)
    torque_metrics = evaluate_clustering(X, torque.labels_)
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Ù†Ù…ÙˆØ¯Ø§Ø± Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ")
        fig = go.Figure()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        fig.add_trace(go.Scatter(
            x=X[:, 0], y=X[:, 1],
            mode='markers',
            marker=dict(color='gray', size=5),
            name='Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ'
        ))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ K-Means
        fig.add_trace(go.Scatter(
            x=X[:, 0], y=X[:, 1],
            mode='markers',
            marker=dict(color=kmeans.labels_, size=5),
            name='K-Means'
        ))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ DBSCAN
        fig.add_trace(go.Scatter(
            x=X[:, 0], y=X[:, 1],
            mode='markers',
            marker=dict(color=dbscan.labels_, size=5),
            name='DBSCAN'
        ))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Torque
        fig.add_trace(go.Scatter(
            x=X[:, 0], y=X[:, 1],
            mode='markers',
            marker=dict(color=torque.labels_, size=5),
            name='Torque'
        ))
        
        fig.update_layout(
            title='Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ',
            xaxis_title='ÙˆÛŒÚ˜Ú¯ÛŒ 1',
            yaxis_title='ÙˆÛŒÚ˜Ú¯ÛŒ 2',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡
        metrics_data = {
            'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…': ['K-Means', 'DBSCAN', 'Torque'],
            'Silhouette Score': [kmeans_metrics[0], dbscan_metrics[0], torque_metrics[0]],
            'Calinski-Harabasz': [kmeans_metrics[1], dbscan_metrics[1], torque_metrics[1]],
            'Davies-Bouldin': [kmeans_metrics[2], dbscan_metrics[2], torque_metrics[2]]
        }
        
        df = pd.DataFrame(metrics_data)
        st.dataframe(df, use_container_width=True)
        
        # ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        st.markdown("""
        ### ØªÙˆØ¶ÛŒØ­ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:
        - **Silhouette Score**: Ù‡Ø±Ú†Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª (Ù…Ø­Ø¯ÙˆØ¯Ù‡: -1 ØªØ§ 1)
        - **Calinski-Harabasz**: Ù‡Ø±Ú†Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª
        - **Davies-Bouldin**: Ù‡Ø±Ú†Ù‡ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª
        """)

with tab2:
    st.markdown("""
    ### ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    
    #### 1. K-Means
    - ÛŒÚ© Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯
    - Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù‚Ø¨Ù„ Ø¯Ø§Ø±Ø¯
    - Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø±ÙˆÛŒ Ùˆ Ø¨Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÛŒÚ©Ø³Ø§Ù†
    - Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø±Ø§Ú©Ø² Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
    
    #### 2. DBSCAN
    - Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú†Ú¯Ø§Ù„ÛŒ
    - Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ù†Ø¯Ø§Ø±Ø¯
    - Ù‚Ø§Ø¯Ø± Ø¨Ù‡ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø´Ú©Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    - Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†ÙˆÛŒØ² Ø±Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ø¯
    - Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ù¾Ø³ÛŒÙ„ÙˆÙ† Ùˆ Ø­Ø¯Ø§Ù‚Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
    
    #### 3. Torque Clustering
    - Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú¯Ø´ØªØ§ÙˆØ±
    - Ø§Ø² Ù…ÙÙ‡ÙˆÙ… Ú¯Ø´ØªØ§ÙˆØ± Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    - Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
    - Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ø¯
    - Ù…Ù‚Ø§ÙˆÙ…â€ŒØªØ± Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ù†ÙˆÛŒØ² Ù†Ø³Ø¨Øª Ø¨Ù‡ K-Means
    """)

with tab3:
    st.markdown("""
    ### Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡
    
    Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±ÙˆÚ˜Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø±Ø³ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù‡Ø¯Ù Ø¢Ù† Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³Øª:
    
    - K-Means (Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ú©Ù„Ø§Ø³ÛŒÚ©)
    - DBSCAN (Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú†Ú¯Ø§Ù„ÛŒ)
    - Torque Clustering (Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ú¯Ø´ØªØ§ÙˆØ±)
    
    #### ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡:
    - Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ ÙØ§Ø±Ø³ÛŒ
    - Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø§ Ø´Ú©Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨ØµØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    - Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù…ÛŒ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    - ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù‡Ø± Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…
    
    #### Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:
    1. Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
    2. ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ùˆ Ù…ÛŒØ²Ø§Ù† Ù†ÙˆÛŒØ² Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
    3. Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
    4. Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± Ù†Ù…ÙˆØ¯Ø§Ø± Ùˆ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯
    
    #### Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡:
    - Streamlit Ø¨Ø±Ø§ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
    - Scikit-learn Ø¨Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    - Plotly Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
    - NumPy Ùˆ Pandas Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    """)

# Ù¾Ø§ÙˆØ±Ù‚ÛŒ
st.markdown("---")
st.markdown("""
Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ â¤ï¸ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†
""")